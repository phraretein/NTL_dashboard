{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt \n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datetime import date\n",
    "from wordcloud import WordCloud, STOPWORDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatlog = pd.read_pickle('./data/chatlog.p') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "td = today.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-cc22a5e8327f>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-cc22a5e8327f>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    df_{}.format(date.today().strftime(%Y-%m-%d)) = df[df._date == {}format(date.today().strftime('%Y-%m-%d'))]\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Clean the chatlog to have only user conversation on specific date\n",
    "def clean_chatlog(chatlog, date=today):\n",
    "    df = chatlog[['userId', 'message', 'role', '_date']] \n",
    "    df = df.loc[df.role=='User']\n",
    "    df_{}.format(date.today().strftime(%Y-%m-%d)) = df[df._date == {}format(date.today().strftime('%Y-%m-%d'))] \n",
    "    return df_{}.format(date.today().strftime(%Y-%m-%d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find top 10 keywords that has the highest TF-IDF average score\n",
    "def top_20_keywords():\n",
    "    vectorizer = TfidfVectorizer(tokenizer=get_th_tokens, token_pattern=None, ngram_range=(1,2)) \n",
    "    vectorizer.fit(df_new['message_filtered_demoji']) \n",
    "    feat_filtered_emoji = vectorizer.transform(df_new['message']) \n",
    "    feat_filtered_emoji_arr = feat_filtered_emoji.toarray() \n",
    "    avg_tfidf = feat_filtered_emoji_arr.sum(axis=0) / np.count_nonzero(feat_filtered_emoji_arr,axis=0) \n",
    "    result_filtered_emoji = pd.DataFrame() \n",
    "    result_filtered_emoji['word'] = vectorizer.get_feature_names() \n",
    "    result_filtered_emoji['avg_tfidf'] = avg_tfidf \n",
    "    return result_filtered_emoji.sort_values('avg_tfidf', ascending=False).head(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def get_th_tokens(text):\n",
    "#     text = text.lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    tokens = word_tokenize(text, engine=\"newmm\", keep_whitespace=False)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean undesired text\n",
    "def clean_text_1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('[.?]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('[0-9]{1,10}', '', text)\n",
    "    text = re.sub('นะ|น่ะ|น่า|น้า','',text)\n",
    "    text = re.sub('คะ|ค่ะ|ค่า|คระ|คร่ะ|คร๊|ค๊','',text)\n",
    "    text = re.sub('ครับ|คับ|คั้บ|ค้าบ|คร้าบ|คาฟ|ค้าฟ|ฮะ|ฮับ|ฮ้าฟ','',text)\n",
    "    text = re.sub('จ้า|จ้ะ|จ๊ะ','',text)\n",
    "    text = re.sub('หน่อย|น่อย','',text)\n",
    "    text = re.sub('สวัสดี|หวัดดี','',text)\n",
    "    text = re.sub('ของ','',text)\n",
    "    # ลบ text ที่อยู่ในวงเล็บ <> ทั้งหมด\n",
    "    text = re.sub(r'<.?>','', text)\n",
    "    # ลบ hashtag\n",
    "    text = re.sub(r'#','',text)\n",
    "    # ลบ separator เช่น \\n \\t\n",
    "    text = ' '.join(text.split())\n",
    "    text = re.sub('สนใจ','',text)\n",
    "    text = re.sub('อยากทราบว่า|อยากทราบ','',text)\n",
    "    text = re.sub('รบกวนสอบถาม|ขอสอบถาม|สอบถาม','',text)\n",
    "    text = re.sub('ปี','',text)\n",
    "    text = re.sub('ขอบคุณ','',text)\n",
    "    text = re.sub('ขอโทษ|ขอโทด','',text)\n",
    "    text = re.sub('ขอ','',text)\n",
    "    text = re.sub('ชั้น','',text)\n",
    "    text = re.sub('เท่าไร|เท่าไหร่|เท่าหรั่ย|เท่าใด|เท่ารัย','',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s):  \n",
    "\n",
    "    # Initialize an empty string \n",
    "    str1 = \" \" \n",
    "      \n",
    "    return (str1.join(s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_digits(text):\n",
    "    output = re.sub(r'\\d+', '', text)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column to store the required string for further process\n",
    "def clean_text_full(df):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_word_cloud(text):\n",
    "    path = './font/THSarabunNew.ttf'\n",
    "    wordcloud = WordCloud(font_path=path, width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                min_font_size = 10, colormap='coolwarm',regexp = r\"[ก-๙a-zA-Z']+\", random_state=1).generate(text) \n",
    "    # Plot the WordCloud image                        \n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "  \n",
    "    plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('NTL': venv)",
   "language": "python",
   "name": "python37464bitntlvenv5bb9f6107ccc44df9d8f2d89f2aa5ff4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
